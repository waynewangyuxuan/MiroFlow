# Agent config: LiveDRBench × Gemini 2.5 Flash × Lab Services + Docker Sandbox
#
# Usage:
#   uv run main.py common-benchmark --config_file_name=agent_livedrbench_gemini_lab
#
# Uses Moonbow Lab Services (serp for search, ulscar for scraping)
# and local Docker sandbox (no E2B cloud dependency).

defaults:
  - benchmark: livedrbench
  - override hydra/job_logging: none
  - _self_

main_agent:
  prompt_class: MainAgentPromptBoxedAnswer
  llm:
    provider_class: "GPTOpenAIClient"
    model_name: "gemini-2.5-flash"
    async_client: true
    temperature: 0.3
    top_p: 0.95
    min_p: 0.0
    top_k: -1
    max_tokens: 32000
    openai_api_key: "${oc.env:GEMINI_API_KEY,???}"
    openai_base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
    keep_tool_result: -1
    oai_tool_thinking: false

  tool_config:
    - tool-lab-serp       # DuckDuckGo search (no quota limit)
    - tool-lab-ulscar     # Resilient web scraping
    - tool-code           # Code execution (Docker sandbox, SANDBOX_BACKEND=docker)

  max_turns: 50
  max_tool_calls_per_turn: 10

  input_process:
    hint_generation: false
    hint_llm_base_url: "${oc.env:HINT_LLM_BASE_URL,https://api.openai.com/v1}"
  output_process:
    final_answer_extraction: false
    final_answer_llm_base_url: "${oc.env:FINAL_ANSWER_LLM_BASE_URL,https://api.openai.com/v1}"

  openai_api_key: "${oc.env:OPENAI_API_KEY,???}"
  add_message_id: true
  keep_tool_result: -1
  chinese_context: "${oc.env:CHINESE_CONTEXT,false}"


sub_agents: null


output_dir: logs/livedrbench/gemini_lab
data_dir: "${oc.env:DATA_DIR,data}"
