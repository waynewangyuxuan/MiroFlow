# Agent config: LiveDRBench × Gemini 2.5 Flash (direct Google AI API)
#
# Usage:
#   uv run main.py common-benchmark --config_file_name=agent_livedrbench_gemini_direct
#
# LiveDRBench tasks are heavy research tasks requiring many search rounds.
# Evaluation is done externally via LiveDRBench's evaluate.py.

defaults:
  - benchmark: livedrbench
  - override hydra/job_logging: none
  - _self_

main_agent:
  prompt_class: MainAgentPromptBoxedAnswer
  llm:
    provider_class: "GPTOpenAIClient"
    model_name: "gemini-2.5-flash"
    async_client: true
    temperature: 0.3
    top_p: 0.95
    min_p: 0.0
    top_k: -1
    max_tokens: 32000
    openai_api_key: "${oc.env:GEMINI_API_KEY,???}"
    openai_base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
    keep_tool_result: -1
    oai_tool_thinking: false

  tool_config:
    - tool-searching

  max_turns: 30        # more turns — deep research tasks need extensive searching
  max_tool_calls_per_turn: 10

  input_process:
    hint_generation: false
    hint_llm_base_url: "${oc.env:HINT_LLM_BASE_URL,https://api.openai.com/v1}"
  output_process:
    final_answer_extraction: false
    final_answer_llm_base_url: "${oc.env:FINAL_ANSWER_LLM_BASE_URL,https://api.openai.com/v1}"

  openai_api_key: "${oc.env:OPENAI_API_KEY,???}"
  add_message_id: true
  keep_tool_result: -1
  chinese_context: "${oc.env:CHINESE_CONTEXT,false}"


sub_agents: null


output_dir: logs/livedrbench/gemini_direct
data_dir: "${oc.env:DATA_DIR,data}"
